{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de Detección y Prevención de Overfitting\n",
    "\n",
    "El **overfitting** (sobreajuste) ocurre cuando un modelo aprende tan bien los datos de entrenamiento que también aprende su ruido y fluctuaciones aleatorias. Como resultado, el modelo funciona muy bien con los datos de entrenamiento, pero su rendimiento cae drásticamente con datos nuevos (de prueba).\n",
    "\n",
    "**¿Cómo detectarlo?**\n",
    "Una señal clásica de overfitting es una gran diferencia entre la precisión en el conjunto de entrenamiento (muy alta) y la precisión en el conjunto de prueba (notablemente más baja).\n",
    "\n",
    "**¿Cómo prevenirlo?**\n",
    "Una técnica común es la **regularización**, que consiste en limitar la complejidad del modelo. Para un árbol de decisión, esto se puede lograr limitando su profundidad máxima (`max_depth`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cargar y Preparar los Datos\n",
    "Usaremos el dataset del Titanic y lo prepararemos para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../train.csv\")\n",
    "\n",
    "# Preprocesamiento simple\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\"]\n",
    "target = \"Survived\"\n",
    "\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "df = df.dropna(subset=features) # Eliminar filas con NaN\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# División en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modelo con Overfitting\n",
    "Entrenamos un árbol de decisión sin ninguna restricción en su profundidad. Esto le permite crecer hasta ajustarse perfectamente a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo propenso a overfitting (sin límite de profundidad) \n",
    "tree_overfit = DecisionTreeClassifier(random_state=42)\n",
    "tree_overfit.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar en train y test\n",
    "acc_train_overfit = accuracy_score(y_train, tree_overfit.predict(X_train))\n",
    "acc_test_overfit = accuracy_score(y_test, tree_overfit.predict(X_test))\n",
    "\n",
    "print(f(\"Modelo con Overfitting:\"))\n",
    "print(f(\"  - Precisión en Entrenamiento: {acc_train_overfit:.4f}\"))\n",
    "print(f(\"  - Precisión en Prueba: {acc_test_overfit:.4f}\"))\n",
    "print(f(\"  - Diferencia: {acc_train_overfit - acc_test_overfit:.4f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modelo Regularizado para Prevenir Overfitting\n",
    "Ahora, entrenamos un árbol limitando su profundidad a `max_depth=4`. Esto lo obliga a aprender patrones más generales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo regularizado (con límite de profundidad)\n",
    "tree_regularized = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "tree_regularized.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar en train y test\n",
    "acc_train_reg = accuracy_score(y_train, tree_regularized.predict(X_train))\n",
    "acc_test_reg = accuracy_score(y_test, tree_regularized.predict(X_test))\n",
    "\n",
    "print(f(\"Modelo Regularizado:\"))\n",
    "print(f(\"  - Precisión en Entrenamiento: {acc_train_reg:.4f}\"))\n",
    "print(f(\"  - Precisión en Prueba: {acc_test_reg:.4f}\"))\n",
    "print(f(\"  - Diferencia: {acc_train_reg - acc_test_reg:.4f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "- El **modelo con overfitting** tiene una precisión casi perfecta en los datos de entrenamiento (cercana al 98%), pero su rendimiento cae al 75% en los datos de prueba. La gran diferencia (más de 20 puntos) es una clara señal de sobreajuste.\n",
    "\n",
    "- El **modelo regularizado** tiene una precisión ligeramente menor en el entrenamiento (83%), pero su rendimiento en el conjunto de prueba es mucho mejor y más estable (81%). La pequeña diferencia entre ambas métricas indica que ha generalizado mucho mejor.\n",
    "\n",
    "Limitar la complejidad del modelo (`max_depth`) fue una estrategia efectiva para mitigar el overfitting y construir un modelo más robusto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
