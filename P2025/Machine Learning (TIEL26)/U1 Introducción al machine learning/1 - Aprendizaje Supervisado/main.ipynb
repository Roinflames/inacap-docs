{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae18ed7d",
   "metadata": {},
   "source": [
    "# Aprendizaje Supervisado - Ejemplo Titanic\n",
    "\n",
    "Este notebook realiza los siguientes pasos:\n",
    "1. Carga los datos de entrenamiento y prueba del Titanic.\n",
    "2. Preprocesa los datos para convertirlos a un formato numérico y manejar valores faltantes.\n",
    "3. Divide los datos de entrenamiento para poder evaluar el modelo.\n",
    "4. Entrena un modelo de clasificación (Random Forest).\n",
    "5. Evalúa el rendimiento del modelo usando la métrica de precisión (accuracy).\n",
    "6. Genera un archivo de predicciones para la competencia de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. Importar librerías necesarias ---\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61013635",
   "metadata": {},
   "source": [
    "## 1. Definición de rutas y variables\n",
    "\n",
    "Definimos las rutas de los archivos y las columnas que usaremos en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ejecutas en Google Colab o Jupyter, adapta las rutas a tu entorno\n",
    "TRAIN_FILE_PATH = \"titanic/train.csv\"\n",
    "TEST_FILE_PATH = \"titanic/test.csv\"\n",
    "SUBMISSION_FILE_PATH = \"submission.csv\"\n",
    "\n",
    "FEATURES = ['Pclass', 'Sex', 'Age']\n",
    "TARGET = 'Survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223bb115",
   "metadata": {},
   "source": [
    "## 2. Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3efe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cargando datos...\")\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_FILE_PATH)\n",
    "    test_df = pd.read_csv(TEST_FILE_PATH)\n",
    "    print(\"Datos cargados exitosamente.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Error: No se encontró el archivo.\")\n",
    "    print(f\"Ruta esperada: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6035e7c",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento de datos\n",
    "- Convertimos la columna `Sex` a numérico.\n",
    "- Rellenamos valores faltantes de `Age` con la **mediana** del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcab340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copias de seguridad para evitar modificaciones no deseadas\n",
    "train_processed = train_df.copy()\n",
    "test_processed = test_df.copy()\n",
    "\n",
    "# Mapear sexos a números\n",
    "sex_mapping = {'male': 0, 'female': 1}\n",
    "train_processed['Sex'] = train_processed['Sex'].map(sex_mapping)\n",
    "test_processed['Sex'] = test_processed['Sex'].map(sex_mapping)\n",
    "\n",
    "# Rellenar NaN en Age con la mediana del train\n",
    "median_age = train_processed['Age'].median()\n",
    "print(f\"Mediana de edad usada: {median_age:.2f}\")\n",
    "\n",
    "train_processed['Age'] = train_processed['Age'].fillna(median_age)\n",
    "test_processed['Age'] = test_processed['Age'].fillna(median_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb719c66",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3391d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir datos en train y validación\n",
    "X = train_processed[FEATURES]\n",
    "y = train_processed[TARGET]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Datos de entrenamiento: {len(X_train)}, Validación: {len(X_val)}\")\n",
    "\n",
    "# Entrenar modelo\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación\n",
    "preds = clf.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, preds)\n",
    "\n",
    "print(f\"Precisión en validación: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11690f2",
   "metadata": {},
   "source": [
    "## 5. Generar archivo de submission para Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en test\n",
    "X_test = test_processed[FEATURES]\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Crear archivo de salida\n",
    "output = pd.DataFrame({\n",
    "    'PassengerId': test_processed.PassengerId,\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "output.to_csv(SUBMISSION_FILE_PATH, index=False)\n",
    "print(f\"Archivo guardado en {SUBMISSION_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6435159",
   "metadata": {},
   "source": [
    "## ✅ Conclusión\n",
    "Hemos construido un pipeline básico de **Aprendizaje Supervisado** con Random Forest\n",
    "para el dataset del Titanic.  \n",
    "Este notebook es fácilmente ampliable:\n",
    "- Se pueden agregar más variables (Fare, SibSp, Embarked, etc.)\n",
    "- Se pueden probar distintos algoritmos de ML.\n",
    "- Se pueden ajustar hiperparámetros con GridSearchCV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
